# 模型配置
model:
  # 音频编码器配置 (使用预训练的 Wav2Vec2 或类似模型作为骨干)
  encoder:
    hidden_size: 1024           # 编码器输出维度或隐藏层大小
    num_layers: 8              # 编码器 Transformer 层数
    num_attention_heads: 12    # 编码器注意力头数
    intermediate_size: 3072    # 编码器 FFN 中间层大小
    hidden_dropout_prob: 0.1   # 编码器隐藏层 Dropout 概率
    attention_probs_dropout_prob: 0.1 # 编码器注意力 Dropout 概率
    max_position_embeddings: 5000 # 位置编码最大长度 (音频帧数量)
    pretrained_model_name: "hugging/wav2vec2-large-xlsr-53-chinese-zh-cn" # 使用的预训练编码器模型名称
    freeze_feature_extractor: false # 冻结特征提取层
    freeze_encoder: false          # 冻结 Transformer 编码器层

  # 文本解码器配置 (使用预训练的 BART 或 T5 解码器部分)
  decoder:
    pretrained_model_name: "hugging/mengzi-t5-base" # 使用的预训练解码器模型名称
    hidden_size: 768           # 解码器隐藏层大小
    num_layers: 12              # 解码器层数
    num_attention_heads: 12     # 解码器注意力头数
    intermediate_size: 3072    # 解码器 FFN 中间层大小
    dropout: 0.3            # 解码器 Dropout  可以尝试稍微提高 Dropout 率（例如从 0.1 提高到 0.2 或 0.3
    max_output_length: 128
    generation_params:
      beam_size: 5            # 使用贪心搜索
      temperature: 0.3         # 确定性生成
      no_repeat_ngram_size: 3  # 禁用n-gram重复检测
      repetition_penalty: 1.0  # 禁用重复惩罚
      max_new_tokens: 50       # 最大生成token数
      ban_extra_ids: true      # 禁用extra_id tokens


  # 长度适配器配置 (连接 Encoder 和 Decoder)
  length_adapter:
    downsample_method: "stride_conv" # [关键] 设定下采样方法为注意力池化  "attention_pooling"
    num_queries: 1024            # [关键] 定义下采样后的目标序列长度，这是一个重要的超参数
    num_layers: 2              # 适配器中自注意力 Transformer 编码器的层数
    num_heads: 8               # 注意力头数
    ffn_dim: 3072             # 前馈网络(FFN)的中间层维度 (推荐值为 decoder.hidden_size * 4, 即 768 * 4)
    dropout: 0.1               # Dropout 比率
    layers: 2                  # CNN 层数
    kernel_size: 3             # 卷积核大小
    architecture: "Transformer" # 标记使用 Transformer 架构
    input_dim: 1024             # 输入维度 (等于 Encoder 输出维度)
    output_dim: 768            # 输出维度 (等于 Decoder 输入维度/hidden_size)
    downsample_kernel_size: 3        # 下采样卷积核大小
    downsample_stride: 4             # 下采样步长
    downsample_padding: 1

    dropout_prob: 0.3
    compression_ratio: 4
    num_transformer_layers: 2
    compression_method: "attention_pooling" # 或 'attention_pooling'
    fixed_output_length: 256  # 不要设 1024（太大）
    num_attention_heads: 8
    transformer_ff_dim: 3072


# 训练配置
training:
  # 基础训练参数
  batch_size: 11         # 训练批次大小
  learning_rate: 0.000001    # 初始学习率 0.00001 0.0001     原来为  0.000005 
  epochs: 200               # 总训练 epoch 数
  log_every: 50            # 每隔多少个批次记录一次训练日志

  # 优化器设置
  optimizer: "AdamW"       # 使用的优化器
  weight_decay: 0.01       # 权重衰减 (L2 正则化)

  # 梯度累积和裁剪
  gradient_accumulation_steps: 4 # 梯度累积步数          原来为1
  gradient_clip_val: 1.0       # 梯度裁剪阈值

  # 学习率调度
  use_scheduler: true      # 是否使用学习率调度器
  scheduler_type: "ReduceLROnPlateau" # 调度器类型
  scheduler_step_size: 5   # StepLR 的步长
  scheduler_gamma: 0.5     # StepLR 的衰减系数


  # 学习率调度
  scheduler:
    use: true               # 是否使用学习率调度器
    name: "ReduceLROnPlateau"          # 调度器类型："StepLR" 或 "ReduceLROnPlateau"
    # StepLR 参数
    step_size: 5            # StepLR 的步长
    gamma: 0.5              # StepLR 的衰减系数
    # ReduceLROnPlateau 参数
    factor: 0.1             # ReduceLROnPlateau 的衰减系数
    patience: 3            # ReduceLROnPlateau 的耐心值
    min_lr: 0.000000000001        # 最小学习率 

  # 检查点与日志设置
  save_every_epochs: 1 # 每隔多少个 epoch 保存一次检查点

  # 用于调试的参数
  debug_subset_size: 10000   # 使用一个小的子集进行快速迭代
  debug_train_subset_size: 0 # 训练集调试子集大小 (0 表示不使用子集)
  debug_val_subset_size: 0    # 验证集调试子集大小 (0 表示不使用子集)
  overfit_single_batch: false # 是否尝试在单个批次上过拟合
  overfit_epochs: 100        # 在单个批次上训练的轮数
  continue_after_overfit: true # 在过拟合测试通过后是否继续完整训练
  overfit_loss_threshold: 0.01 # 单批次过拟合测试的目标损失阈值
  log_batch_every: 50      # 每隔多少个批次记录一次训练日志
  # 新增的训练控制参数
  # 继续训练设置
  resume_training: true    # 是否继续上次的训练 outputs/run_20250611_162132/checkpoints/model_epoch70.pth
  checkpoint_path: "outputs/run_20250924_221521/checkpoints/latest_model_epoch51.pth"       # 继续训练时加载的检查点路径outputs/run_20250611_162132/checkpoints/model_epoch25.pth
  start_epoch: 0            # 继续训练时的起始轮数（0表示从头开始）
  output_dir: "outputs"     # 输出目录，所有训练结果都保存在此目录下
  run_name: ""              # 训练运行的名称，如果为空则自动生成时间戳名称
  resume_from_run: "run_20250924_221521"       # 要继续训练的运行文件夹名称，如"run_20250611_151731"


  plot_on_interrupt: true     # 当用户中断训练时是否立即绘图

# 数据配置
data:
  # 数据路径
  audio_root_dir: "data/raw/audio" # 指向包含 train/dev/test 音频子目录的父目录
  # train_txt: "data/aishell_ner_transcript.train.txt" # 训练集标注 TXT 文件路径
  # val_txt: "data/aishell_ner_transcript.dev.txt"   # 验证集标注 TXT 文件路径
  # test_txt: "data/aishell_ner_transcript.test.txt" # 测试集标注 TXT 文件路径

  train_txt: "data/aishell_ner_transcript.train.new.txt"
  val_txt: "data/aishell_ner_transcript.dev.new.txt"
  test_txt: "data/aishell_ner_transcript.test.new.txt"
  # Seq2Seq 输出配置
  max_output_length: 40 # 生成文本序列的最大长度

  # 数据处理参数
  sample_rate: 16000              # 音频原始或目标采样率
  num_workers: 0 # DataLoader 工作进程数量

  # 文本词汇表构建配置
  text_special_tokens: ['<PAD>', '<SOS>', '<EOS>', '<UNK>', '<PER_START>', '<PER_END>', '<LOC_START>', '<LOC_END>', '<ORG_START>', '<ORG_END>']
  text_min_freq: 1 # 文本词汇表最小出现频率

  use_preprocessed_features: false
  preprocessed_features_dir: "data/preprocessed_features"  # 预处理特征的根目录
  # 波形数据增强配置
  waveform_augment_prob: 0.5 # 波形增强概率

# 推理配置
inference:
  # 解码策略配置
  max_length: 256          # [关键] 确保这个值足够大
  num_beams: 4             # [推荐] 使用 Beam Search (设置为 1 则为 Greedy Search)
  repetition_penalty: 1.2  # (可选) 避免生成重复内容
  
  # 调试相关的推理参数
  debug_specific_audio_ids: [] 

# 日志配置
logging:
  level: DEBUG  # INFO #DEBUG  # 日志级别

# 测试配置
testing:
  model_path: "outputs/run_20250611_162132/checkpoints/best_model_epoch22_loss0.3680.pth"  # 最佳模型路径
  batch_size: 20
  num_workers: 0
  output_dir: "outputs/test_results"
  device: "cuda"  # 或 "cpu"  